{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11921284,"sourceType":"datasetVersion","datasetId":7494812}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nfrom PIL import Image\nfrom sklearn.metrics import f1_score\nfrom sklearn.preprocessing import LabelEncoder\nfrom torchvision import transforms, models\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, Dataset\nfrom tqdm import tqdm","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-23T12:34:38.058810Z","iopub.execute_input":"2025-05-23T12:34:38.059044Z","iopub.status.idle":"2025-05-23T12:34:47.636792Z","shell.execute_reply.started":"2025-05-23T12:34:38.059019Z","shell.execute_reply":"2025-05-23T12:34:47.636191Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"TRAIN_IMG_PATH = \"/kaggle/input/soil-classification-dataset/soil_classification-2025/train\"\nTEST_IMG_PATH = \"/kaggle/input/soil-classification-dataset/soil_classification-2025/test\"\nTRAIN_LABELS = \"/kaggle/input/soil-classification-dataset/soil_classification-2025/train_labels.csv\"\nTEST_IDS = \"/kaggle/input/soil-classification-dataset/soil_classification-2025/test_ids.csv\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T12:34:47.637888Z","iopub.execute_input":"2025-05-23T12:34:47.638254Z","iopub.status.idle":"2025-05-23T12:34:47.641753Z","shell.execute_reply.started":"2025-05-23T12:34:47.638235Z","shell.execute_reply":"2025-05-23T12:34:47.641054Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df = pd.read_csv(TRAIN_LABELS)\nle = LabelEncoder()\ntrain_df['label'] = le.fit_transform(train_df['soil_type'])  # 0 to 3\nclass_names = le.classes_","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T12:34:47.642448Z","iopub.execute_input":"2025-05-23T12:34:47.642684Z","iopub.status.idle":"2025-05-23T12:34:47.685563Z","shell.execute_reply.started":"2025-05-23T12:34:47.642669Z","shell.execute_reply":"2025-05-23T12:34:47.685098Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class SoilDataset(Dataset):\n    def __init__(self, df, img_dir, transform=None, test=False):\n        self.df = df\n        self.img_dir = img_dir\n        self.transform = transform\n        self.test = test\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        image_id = self.df.iloc[idx]['image_id']\n        image = Image.open(os.path.join(self.img_dir, image_id)).convert(\"RGB\")\n        if self.transform:\n            image = self.transform(image)\n        if self.test:\n            return image, image_id\n        else:\n            label = self.df.iloc[idx]['label']\n            return image, label","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T12:34:47.686704Z","iopub.execute_input":"2025-05-23T12:34:47.686898Z","iopub.status.idle":"2025-05-23T12:34:47.691889Z","shell.execute_reply.started":"2025-05-23T12:34:47.686882Z","shell.execute_reply":"2025-05-23T12:34:47.691240Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.5]*3, [0.5]*3)\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T12:34:47.692546Z","iopub.execute_input":"2025-05-23T12:34:47.692761Z","iopub.status.idle":"2025-05-23T12:34:47.708575Z","shell.execute_reply.started":"2025-05-23T12:34:47.692746Z","shell.execute_reply":"2025-05-23T12:34:47.707935Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_dataset = SoilDataset(train_df, TRAIN_IMG_PATH, transform=transform)\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T12:34:47.709142Z","iopub.execute_input":"2025-05-23T12:34:47.709450Z","iopub.status.idle":"2025-05-23T12:34:47.723528Z","shell.execute_reply.started":"2025-05-23T12:34:47.709435Z","shell.execute_reply":"2025-05-23T12:34:47.722878Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Load model with new syntax to avoid warning\nfrom torchvision.models import resnet18, ResNet18_Weights\nmodel = resnet18(weights=ResNet18_Weights.DEFAULT)\nmodel.fc = nn.Linear(model.fc.in_features, 4)  # 4 classes\nmodel = model.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T12:34:47.724105Z","iopub.execute_input":"2025-05-23T12:34:47.724334Z","iopub.status.idle":"2025-05-23T12:34:48.554696Z","shell.execute_reply.started":"2025-05-23T12:34:47.724314Z","shell.execute_reply":"2025-05-23T12:34:48.554161Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nfrom torch import nn\nfrom tqdm import tqdm\nfrom sklearn.metrics import f1_score\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n\nepochs = 100\nmodel.to(device)\nmodel.train()\n\nfor epoch in range(epochs):\n    running_loss = 0\n    all_preds, all_labels = [], []\n\n    for images, labels in tqdm(train_loader):\n        images, labels = images.to(device), labels.to(device)\n\n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n        all_preds.extend(torch.argmax(outputs, dim=1).cpu().numpy())\n        all_labels.extend(labels.cpu().numpy())\n\n    scheduler.step()\n    f1 = f1_score(all_labels, all_preds, average='macro')\n    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(train_loader):.4f}, F1 Score: {f1:.6f}\")\n\n    if f1 == 1.0:\n        print(\"Perfect F1 Score achieved! Stopping training.\")\n        break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T12:34:48.555303Z","iopub.execute_input":"2025-05-23T12:34:48.555536Z","iopub.status.idle":"2025-05-23T12:43:34.181690Z","shell.execute_reply.started":"2025-05-23T12:34:48.555509Z","shell.execute_reply":"2025-05-23T12:43:34.180788Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import f1_score\n\nmodel.eval()\nall_preds, all_labels = [], []\n\nwith torch.no_grad():\n    for images, labels in train_loader:  # use full, unshuffled train_loader here\n        images, labels = images.to(device), labels.to(device)\n        outputs = model(images)\n        preds = torch.argmax(outputs, dim=1)\n\n        all_preds.extend(preds.cpu().numpy())\n        all_labels.extend(labels.cpu().numpy())\n\ntrain_f1 = f1_score(all_labels, all_preds, average='macro')\nprint(f\"F1 Score (Train - Full Evaluation): {train_f1:.10f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T12:54:38.718604Z","iopub.execute_input":"2025-05-23T12:54:38.719315Z","iopub.status.idle":"2025-05-23T12:54:49.453300Z","shell.execute_reply.started":"2025-05-23T12:54:38.719293Z","shell.execute_reply":"2025-05-23T12:54:49.452514Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_df = pd.read_csv(TEST_IDS)\ntest_dataset = SoilDataset(test_df, TEST_IMG_PATH, transform=transform, test=True)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n\nmodel.eval()\npredictions = []\nimage_ids = []\n\nwith torch.no_grad():\n    for images, ids in test_loader:\n        images = images.cuda()\n        outputs = model(images)\n        preds = torch.argmax(outputs, 1).cpu().numpy()\n        predictions.extend(preds)\n        image_ids.extend(ids)\n\nsubmission = pd.DataFrame({\n    \"image_id\": image_ids,\n    \"soil_type\": le.inverse_transform(predictions)\n})\n\nsubmission.to_csv(\"submission.csv\", index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T12:43:44.752168Z","iopub.execute_input":"2025-05-23T12:43:44.753347Z","iopub.status.idle":"2025-05-23T12:43:48.611055Z","shell.execute_reply.started":"2025-05-23T12:43:44.753328Z","shell.execute_reply":"2025-05-23T12:43:48.610276Z"}},"outputs":[],"execution_count":null}]}